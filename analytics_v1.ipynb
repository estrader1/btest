{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84b4f2f1-2832-4cf8-be45-39c5003f8abf",
   "metadata": {},
   "source": [
    "### read data and calc returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5150f59-564b-4600-8b72-8764a2b54fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('data.csv', parse_dates = True).set_index(['ID','DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "081434fc-a252-41d9-bc42-53a8fc780834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.index.duplicated()].reset_index() # causes multiindex issues later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ffedea8b-400e-4798-8f61-0b788dffe697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 18)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ee7cb-0972-48f5-a1d3-a251a7d371c6",
   "metadata": {},
   "source": [
    "### functions - ret calc and makeready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96829952-4a5b-4de6-87bb-943fe9f14e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_returns(df):\n",
    "    \"\"\"Helper function to calculate returns and excess returns\"\"\"\n",
    "    df = df.copy()\n",
    "    df['stock_return'] = df.groupby('ID')['px_last_splits'].pct_change()\n",
    "    df['spy_return'] = df.groupby('ID')['spy_splits'].pct_change()\n",
    "    df['stock_excess_return'] = df['stock_return'] - df['spy_return']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dfed4a-6c12-4b5a-bd76-a7108179e09f",
   "metadata": {},
   "source": [
    "### functions - rolling reg / var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "805835de-d3a1-4cfa-85e8-fa525111f53e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def rolling_residual_variance(df, window_size, dependent_var, independent_vars):\n",
    "    \"\"\"\n",
    "    Performs rolling regression in parallel using joblib.\n",
    "\n",
    "    Args:\n",
    "        df: Pandas DataFrame containing the data.\n",
    "        window_size: Size of the rolling window.\n",
    "        dependent_var: Name of the dependent variable column.\n",
    "        independent_vars: List of names of independent variable columns.\n",
    "\n",
    "    Returns:\n",
    "        Pandas DataFrame with the regression coefficients for each window.\n",
    "        Returns None if there are issues.\n",
    "    \"\"\"\n",
    "\n",
    "    n_rows = len(df)\n",
    "    results = []\n",
    "\n",
    "    def _regress_window(i):\n",
    "        if i < window_size -1:\n",
    "            return None # Handle edge cases at beginning of dataframe\n",
    "        window_data = df.iloc[i - window_size + 1:i + 1]\n",
    "\n",
    "        X = window_data[independent_vars].values\n",
    "        y = window_data[dependent_var].values.reshape(-1,1) # Reshape y for sklearn\n",
    "\n",
    "        if len(window_data) < window_size or np.any(np.isnan(X)) or np.any(np.isnan(y)):\n",
    "            return None  # Handle cases where the window is incomplete or contains NaNs.\n",
    "        \n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y)\n",
    "        y_pred = model.predict(X)\n",
    "\n",
    "        # Step 3: Calculate the residuals\n",
    "        residuals = y - y_pred\n",
    "\n",
    "        # Step 4: Compute the residual variance\n",
    "        residual_variance = np.var(residuals, ddof=1) \n",
    "\n",
    "        return {'index': df.index[i], 'residual_variance': residual_variance} # Include index for proper merging\n",
    "\n",
    "\n",
    "    results = Parallel(n_jobs=-1)(delayed(_regress_window)(i) for i in range(n_rows))\n",
    "    \n",
    "    \n",
    "\n",
    "    # Filter out None results (from edge cases or NaN windows)\n",
    "    valid_results = [r for r in results if r is not None]\n",
    "\n",
    "    if not valid_results: # Check if all results are invalid\n",
    "        return None\n",
    "\n",
    "    results_df = pd.DataFrame(valid_results)#.set_index('index')\n",
    "    \n",
    "    # Handle multiindex\n",
    "    if isinstance(results_df['index'].iloc[0], tuple):\n",
    "        results_df[list(df.index.names)] = results_df['index'].apply(pd.Series)\n",
    "        results_df = results_df.drop(columns='index').set_index(list(df.index.names))\n",
    "    else:\n",
    "        results_df = results_df.set_index('index')\n",
    "        \n",
    "    return results_df\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# # def rolling_regression(df, window_size, dependent_var, independent_vars, reg_type='OLS', alpha=1.0):\n",
    "# #     \"\"\"\n",
    "# #     Performs rolling regression in parallel using joblib, with options for OLS, Ridge, and Lasso.\n",
    "\n",
    "# #     Args:\n",
    "# #         df: Pandas DataFrame containing the data.\n",
    "# #         window_size: Size of the rolling window.\n",
    "# #         dependent_var: Name of the dependent variable column.\n",
    "# #         independent_vars: List of names of independent variable columns.\n",
    "# #         reg_type: Type of regression to perform ('OLS', 'Ridge', 'Lasso'). Default is 'OLS'.\n",
    "# #         alpha: Regularization strength for Ridge and Lasso. Default is 1.0.\n",
    "\n",
    "# #     Returns:\n",
    "# #         Pandas DataFrame with the regression coefficients for each window, indexed by the original DataFrame's index.\n",
    "# #         Returns None if there are issues.\n",
    "# #     \"\"\"\n",
    "\n",
    "# #     n_rows = len(df)\n",
    "# #     results = []\n",
    "\n",
    "# #     def _regress_window(i):\n",
    "# #         if i < window_size -1:\n",
    "# #             return None # Handle edge cases at beginning of dataframe\n",
    "# #         window_data = df.iloc[i - window_size + 1:i + 1]\n",
    "\n",
    "# #         X = window_data[independent_vars].values\n",
    "# #         y = window_data[dependent_var].values.reshape(-1,1) # Reshape y for sklearn\n",
    "\n",
    "# #         if len(window_data) < window_size or np.any(np.isnan(X)) or np.any(np.isnan(y)):\n",
    "# #             return None  # Handle cases where the window is incomplete or contains NaNs.\n",
    "\n",
    "# #         if reg_type.upper() == 'OLS':\n",
    "# #             model = LinearRegression()\n",
    "# #         elif reg_type.upper() == 'RIDGE':\n",
    "# #             model = Ridge(alpha=alpha)\n",
    "# #         elif reg_type.upper() == 'LASSO':\n",
    "# #             model = Lasso(alpha=alpha)\n",
    "# #         else:\n",
    "# #             raise ValueError(\"Invalid reg_type. Choose 'OLS', 'Ridge', or 'Lasso'.\")\n",
    "\n",
    "# #         model.fit(X, y)\n",
    "# #         coefs = model.coef_.flatten() # Flatten the coefficients to a 1D array\n",
    "# #         intercept = model.intercept_\n",
    "\n",
    "# #         return {'index': df.index[i], 'intercept': intercept, **dict(zip(independent_vars, coefs))} # Include index for proper merging\n",
    "\n",
    "\n",
    "# #     results = Parallel(n_jobs=-1)(delayed(_regress_window)(i) for i in range(n_rows))\n",
    "\n",
    "# #     # Filter out None results (from edge cases or NaN windows)\n",
    "# #     valid_results = [r for r in results if r is not None]\n",
    "\n",
    "# #     if not valid_results: # Check if all results are invalid\n",
    "# #         return None\n",
    "\n",
    "# #     results_df = pd.DataFrame(valid_results)#.set_index('index')\n",
    "    \n",
    "# #     # handle multiinex\n",
    "# #     if(isinstance(results_df['index'].iloc[0],tuple)):\n",
    "# #         results_df[list(df.index.names)] = results_df['index'].apply(pd.Series)\n",
    "# #         results_df = results_df.drop(columns = 'index').set_index(list(df.index.names))\n",
    "    \n",
    "# #     return results_df\n",
    "\n",
    "def rolling_regression(df, window_size, dependent_var, independent_vars, reg_type='OLS', alpha=1.0):\n",
    "    \"\"\"\n",
    "    Performs rolling regression in parallel using joblib, with options for OLS, Ridge, and Lasso.\n",
    "    Returns np.nan for coefficients when X or y contains NaN values.\n",
    "\n",
    "    Args:\n",
    "        df: Pandas DataFrame containing the data.\n",
    "        window_size: Size of the rolling window.\n",
    "        dependent_var: Name of the dependent variable column.\n",
    "        independent_vars: List of names of independent variable columns.\n",
    "        reg_type: Type of regression to perform ('OLS', 'Ridge', 'Lasso'). Default is 'OLS'.\n",
    "        alpha: Regularization strength for Ridge and Lasso. Default is 1.0.\n",
    "\n",
    "    Returns:\n",
    "        Pandas DataFrame with the regression coefficients for each window, indexed by the original DataFrame's index.\n",
    "        Returns None if there are issues.\n",
    "    \"\"\"\n",
    "\n",
    "    n_rows = len(df)\n",
    "    results = []\n",
    "\n",
    "    def _regress_window(i):\n",
    "        if i < window_size - 1:\n",
    "            return {'index': df.index[i],\n",
    "                   'intercept': np.nan,\n",
    "                   **dict(zip(independent_vars, [np.nan] * len(independent_vars)))}\n",
    "\n",
    "        window_data = df.iloc[i - window_size + 1:i + 1]\n",
    "\n",
    "        X = window_data[independent_vars].values\n",
    "        y = window_data[dependent_var].values.reshape(-1,1)\n",
    "\n",
    "        # Return NaN coefficients if window contains NaN or is incomplete\n",
    "        if len(window_data) < window_size or np.any(np.isnan(X)) or np.any(np.isnan(y)):\n",
    "            return {'index': df.index[i],\n",
    "                   'intercept': np.nan,\n",
    "                   **dict(zip(independent_vars, [np.nan] * len(independent_vars)))}\n",
    "\n",
    "        if reg_type.upper() == 'OLS':\n",
    "            model = LinearRegression()\n",
    "        elif reg_type.upper() == 'RIDGE':\n",
    "            model = Ridge(alpha=alpha)\n",
    "        elif reg_type.upper() == 'LASSO':\n",
    "            model = Lasso(alpha=alpha)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid reg_type. Choose 'OLS', 'Ridge', or 'Lasso'.\")\n",
    "\n",
    "        model.fit(X, y)\n",
    "        coefs = model.coef_.flatten()\n",
    "        intercept = model.intercept_\n",
    "\n",
    "        return {'index': df.index[i], 'intercept': intercept, **dict(zip(independent_vars, coefs))}\n",
    "\n",
    "    results = Parallel(n_jobs=-1)(delayed(_regress_window)(i) for i in range(n_rows))\n",
    "\n",
    "    # All results should be valid now since we're returning NaN instead of None\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Handle multiindex\n",
    "    if isinstance(results_df['index'].iloc[0], tuple):\n",
    "        results_df[list(df.index.names)] = results_df['index'].apply(pd.Series)\n",
    "        results_df = results_df.drop(columns='index').set_index(list(df.index.names))\n",
    "    else:\n",
    "        results_df = results_df.set_index('index')\n",
    "\n",
    "    return results_df\n",
    "\n",
    "# def rolling_regression(df, window_size, dependent_var, independent_vars):\n",
    "#     \"\"\"\n",
    "#     Performs rolling regression in parallel using joblib.\n",
    "\n",
    "#     Args:\n",
    "#         df: Pandas DataFrame containing the data.\n",
    "#         window_size: Size of the rolling window.\n",
    "#         dependent_var: Name of the dependent variable column.\n",
    "#         independent_vars: List of names of independent variable columns.\n",
    "\n",
    "#     Returns:\n",
    "#         Pandas DataFrame with the regression coefficients for each window.\n",
    "#         Returns None if there are issues.\n",
    "#     \"\"\"\n",
    "\n",
    "#     n_rows = len(df)\n",
    "#     results = []\n",
    "\n",
    "#     def _regress_window(i):\n",
    "#         if i < window_size -1:\n",
    "#             return None # Handle edge cases at beginning of dataframe\n",
    "#         window_data = df.iloc[i - window_size + 1:i + 1]\n",
    "\n",
    "#         X = window_data[independent_vars].values\n",
    "#         y = window_data[dependent_var].values.reshape(-1,1) # Reshape y for sklearn\n",
    "\n",
    "#         if len(window_data) < window_size or np.any(np.isnan(X)) or np.any(np.isnan(y)):\n",
    "#             return None  # Handle cases where the window is incomplete or contains NaNs.\n",
    "        \n",
    "#         model = LinearRegression()\n",
    "#         model.fit(X, y)\n",
    "#         coefs = model.coef_.flatten() # Flatten the coefficients to a 1D array\n",
    "#         intercept = model.intercept_\n",
    "\n",
    "#         return {'index': df.index[i], 'intercept': intercept, **dict(zip(independent_vars, coefs))} # Include index for proper merging\n",
    "\n",
    "\n",
    "#     results = Parallel(n_jobs=-1)(delayed(_regress_window)(i) for i in range(n_rows))\n",
    "\n",
    "#     # Filter out None results (from edge cases or NaN windows)\n",
    "#     valid_results = [r for r in results if r is not None]\n",
    "\n",
    "#     if not valid_results: # Check if all results are invalid\n",
    "#         return None\n",
    "\n",
    "#     results_df = pd.DataFrame(valid_results).set_index('index')\n",
    "#     return results_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2033c2a9-5a5f-453c-8db9-f4b21374fd76",
   "metadata": {},
   "source": [
    "### calculate metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07a947e8-2cc8-442a-89da-24bffc9bb178",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = calculate_returns(df).set_index(['ID','DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701e2fa4-edb6-4bd6-b7bd-bbe3c583502a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76a5d9b1-81b2-4a39-be75-7fe982a10267",
   "metadata": {},
   "source": [
    "### technical factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "81939a38-1777-49ea-a478-5a95ae2f5269",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf['beta'] = mdf\\\n",
    ".groupby('ID', group_keys = False).apply(lambda x: rolling_regression(x, window_size = 24 , dependent_var = 'stock_return', independent_vars = ['spy_return']))\\\n",
    ".drop(columns = 'intercept')\\\n",
    ".rename(columns = {'spy_return':'beta'})\n",
    "\n",
    "mdf['volatility'] = mdf.groupby('ID',group_keys = False)['stock_return'].rolling(24).std().mul(np.sqrt(12)).reset_index(level = 0, drop = True).rename('volatility')\n",
    "\n",
    "mdf['avg_volm_to_cap'] = mdf.groupby('ID', group_keys = False).apply(lambda x: x['px_volume'].rolling(12).mean()/(x['cur_mkt_cap']/1000000)).rename('avg_volm_to_cap')\n",
    "\n",
    "\n",
    "mdf['volume_trend'] = mdf.groupby('ID', group_keys = False).apply(lambda x: rolling_regression(x.assign(trend = lambda x:np.arange(len(x))), window_size = 24 , dependent_var = 'px_volume', independent_vars = ['trend'])).rename(columns = {'trend':'volume_trend'}).drop(columns = 'intercept')\n",
    "\n",
    "\n",
    "\n",
    "mdf['residual_variance'] = mdf.groupby('ID', group_keys = False).apply(lambda x: rolling_residual_variance(x, window_size = 24 , dependent_var = 'stock_return', independent_vars = ['spy_return']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "60740c26-8a26-449a-a2ea-3910aebe749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compound_returns(returns):\n",
    "    return (1 + returns).prod() - 1\n",
    "\n",
    "# List of rolling periods to calculate\n",
    "periods = [1, 2, 3, 6, 12]\n",
    "\n",
    "# Calculate rolling compounded returns for each period\n",
    "for period in periods:\n",
    "    # Stock returns\n",
    "    mdf[f'stock_return_{period}m'] = mdf.groupby('ID')['stock_return'].rolling(\n",
    "        window=period, min_periods=period\n",
    "    ).apply(compound_returns).reset_index(level = 0, drop = True).values\n",
    "\n",
    "    # SPY returns\n",
    "    mdf[f'spy_return_{period}m'] = mdf.groupby('ID')['spy_return'].rolling(\n",
    "        window=period, min_periods=period\n",
    "    ).apply(compound_returns).reset_index(level = 0, drop = True).values\n",
    "\n",
    "    # Calculate excess returns (stock - spy)\n",
    "    mdf[f'rs_{period}m'] = mdf[f'stock_return_{period}m'] - mdf[f'spy_return_{period}m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd43d574-05a4-4400-b0c3-325e800698ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf['3mrs_3mago'] = mdf.groupby('ID')['rs_3m'].shift(3)\n",
    "mdf['3mrs_6mago'] = mdf.groupby('ID')['rs_3m'].shift(6)\n",
    "mdf['3mrs_9mago'] = mdf.groupby('ID')['rs_3m'].shift(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7d3c92-c1e5-4eaa-b948-0fa50d85b630",
   "metadata": {},
   "source": [
    "### value factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7984e12f-db95-44b0-8c8a-6ddde4035c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# earnings to price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1607a63-3a55-4f0f-b9f1-c6444b94c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf['eps_to_price'] = mdf.groupby('ID').apply(lambda x: x['eps']/x['px_last_splits']).reset_index(0, drop = True)\n",
    "\n",
    "\n",
    "mdf['eps_to_price_trend']= mdf.groupby('ID', group_keys = False)\\\n",
    ".apply(lambda x: rolling_regression(x.assign(trend = lambda x:np.arange(len(x))), window_size = 24 , dependent_var = 'eps_to_price', independent_vars = ['trend']))\\\n",
    ".rename(columns = {'trend':'eps_to_price_trend'}).drop(columns = 'intercept')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "beb0b4cb-45f7-4b74-87b7-04e6d867cf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sales to price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb8480d-892a-4371-be6d-086c4dfb8da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "63501266-5c3c-42c3-afce-6638cdf97e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf['sales_to_price'] = mdf.groupby('ID').apply(lambda x: x['sales']/x['px_last_splits']).reset_index(0, drop = True)\n",
    "\n",
    "\n",
    "mdf['sales_to_price_trend']= mdf.groupby('ID', group_keys = False)\\\n",
    ".apply(lambda x: rolling_regression(x.assign(trend = lambda x:np.arange(len(x))), window_size = 24 , dependent_var = 'sales_to_price', independent_vars = ['trend']))\\\n",
    ".rename(columns = {'trend':'sales_to_price_trend'}).drop(columns = 'intercept')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ec6717c-6556-4bb5-87a7-6156c7d4668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cash to price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9a77f91f-f957-4121-baa7-1364e3913ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf['fcf_calc'] = mdf['cfo_ltm_a'] + mdf['capex'] + mdf['dvd'] \n",
    "\n",
    "mdf['cash_to_price'] = mdf['fcf_calc'] / mdf['px_last_splits']\n",
    "\n",
    "mdf['cash_to_price_trend']= mdf.groupby('ID', group_keys = False)\\\n",
    ".apply(lambda x: rolling_regression(x.assign(trend = lambda x:np.arange(len(x))), window_size = 24 , dependent_var = 'cash_to_price', independent_vars = ['trend']))\\\n",
    ".rename(columns = {'trend':'cash_to_price_trend'}).drop(columns = 'intercept')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d76ffa15-18ad-46be-8ad7-c90220cae30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividend to price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "be2898b4-054b-4d0f-90b6-586d2487860e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf['div_to_price'] = np.abs(mdf['dvd']) / mdf['px_last_splits']\n",
    "\n",
    "mdf['div_to_price_trend']= mdf.groupby('ID', group_keys = False)\\\n",
    ".apply(lambda x: rolling_regression(x.assign(trend = lambda x:np.arange(len(x))), window_size = 24 , dependent_var = 'div_to_price', independent_vars = ['trend']))\\\n",
    ".rename(columns = {'trend':'div_to_price_trend'}).drop(columns = 'intercept')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2354adda-5784-4d19-8d50-fba04d4695b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# book to price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "15bf8cca-9026-4ee1-9f50-91efcef1d7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf['book_to_price'] = mdf['book_value'] / mdf['cur_mkt_cap']\n",
    "\n",
    "mdf['book_to_price_trend']= mdf.groupby('ID', group_keys = False)\\\n",
    ".apply(lambda x: rolling_regression(x.assign(trend = lambda x:np.arange(len(x))), window_size = 24 , dependent_var = 'book_to_price', independent_vars = ['trend']))\\\n",
    ".rename(columns = {'trend':'book_to_price_trend'}).drop(columns = 'intercept')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d454fcd6-f6c4-4b34-8c84-b304902be080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'px_last_splits',\n",
       " 'px_last_full',\n",
       " 'cur_mkt_cap',\n",
       " 'px_volume',\n",
       " 'spy_splits',\n",
       " 'spy_tr',\n",
       " 'eps',\n",
       " 'sales',\n",
       " 'cfo_ltm_a',\n",
       " 'fcf_ltm_a',\n",
       " 'capex',\n",
       " 'dvd',\n",
       " 'opmargin1',\n",
       " 'book_value',\n",
       " 'shares_outstanding',\n",
       " 'stock_return',\n",
       " 'spy_return',\n",
       " 'stock_excess_return',\n",
       " 'beta',\n",
       " 'volatility',\n",
       " 'avg_volm_to_cap',\n",
       " 'volume_trend',\n",
       " 'residual_variance',\n",
       " 'stock_return_1m',\n",
       " 'spy_return_1m',\n",
       " 'rs_1m',\n",
       " 'stock_return_2m',\n",
       " 'spy_return_2m',\n",
       " 'rs_2m',\n",
       " 'stock_return_3m',\n",
       " 'spy_return_3m',\n",
       " 'rs_3m',\n",
       " 'stock_return_6m',\n",
       " 'spy_return_6m',\n",
       " 'rs_6m',\n",
       " 'stock_return_12m',\n",
       " 'spy_return_12m',\n",
       " 'rs_12m',\n",
       " '3mrs_3mago',\n",
       " '3mrs_6mago',\n",
       " '3mrs_9mago',\n",
       " 'eps_to_price',\n",
       " 'eps_to_price_trend',\n",
       " 'sales_to_price',\n",
       " 'sales_to_price_trend',\n",
       " 'fcf_calc',\n",
       " 'cash_to_price',\n",
       " 'cash_to_price_trend',\n",
       " 'div_to_price',\n",
       " 'div_to_price_trend',\n",
       " 'book_to_price',\n",
       " 'book_to_price_trend']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0fefe581-520e-4ac1-8bd5-a0e255ed5239",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = mdf[['stock_return',\n",
    "           'cur_mkt_cap',\n",
    "           'px_last_splits',\n",
    "           'beta',\n",
    "             'volatility',\n",
    "             'avg_volm_to_cap',\n",
    "             'volume_trend',\n",
    "             'residual_variance',\n",
    "             'stock_return_1m',\n",
    "             'rs_1m',\n",
    "             'stock_return_2m',\n",
    "\n",
    "             'rs_2m',\n",
    "             'stock_return_3m',\n",
    "\n",
    "             'rs_3m',\n",
    "             'stock_return_6m',\n",
    "\n",
    "             'rs_6m',\n",
    "             'stock_return_12m',\n",
    "\n",
    "             'rs_12m',\n",
    "             '3mrs_3mago',\n",
    "             '3mrs_6mago',\n",
    "             '3mrs_9mago',\n",
    "             'eps_to_price',\n",
    "             'eps_to_price_trend',\n",
    "             'sales_to_price',\n",
    "             'sales_to_price_trend',\n",
    "             'fcf_calc',\n",
    "             'cash_to_price',\n",
    "             'cash_to_price_trend',\n",
    "             'div_to_price',\n",
    "             'div_to_price_trend',\n",
    "             'book_to_price',\n",
    "             'book_to_price_trend']]\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1240b928-9da7-4476-abd4-ff68c33c928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcols = fdf.columns.to_list()\n",
    "fcols.remove('stock_return')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9a2a7a63-c260-4f25-bdd1-a6ee8583bbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = fdf.groupby('DATE').transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8a5663d4-3835-4568-a76b-c85dbcf97f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sw/kl2bvz9d5275zz0p278kz9nc0000gn/T/ipykernel_25227/1195038977.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fdf[fcols] = fdf[fcols].groupby('DATE').transform(lambda x: zscore(x).clip(-3,3))\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# df[numcols] = df[numcols].groupby('ITERATION_DATE').transform(lambda x: winsorize(x, limits = (0.01,0.01)))\n",
    "fdf[fcols] = fdf[fcols].groupby('DATE').transform(lambda x: zscore(x).clip(-3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fa33b5a6-fe0a-4ab1-9854-31c214a8a071",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sw/kl2bvz9d5275zz0p278kz9nc0000gn/T/ipykernel_25227/1522773138.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fdf[fcols] = fdf.groupby(level = 'ID')[fcols].shift(1)\n"
     ]
    }
   ],
   "source": [
    "fdf[fcols] = fdf.groupby(level = 'ID')[fcols].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "056eb4fc-2d77-472f-b96b-17dae19f65ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = fdf\\\n",
    ".groupby('DATE', group_keys = False).apply(lambda x: rolling_regression(x, window_size = 24 , dependent_var = 'stock_return', independent_vars = fcols))\\\n",
    ".drop(columns = 'intercept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e9ab9cce-1a38-4da7-801f-edeb81f7c131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cur_mkt_cap</th>\n",
       "      <th>px_last_splits</th>\n",
       "      <th>beta</th>\n",
       "      <th>volatility</th>\n",
       "      <th>avg_volm_to_cap</th>\n",
       "      <th>volume_trend</th>\n",
       "      <th>residual_variance</th>\n",
       "      <th>stock_return_1m</th>\n",
       "      <th>rs_1m</th>\n",
       "      <th>stock_return_2m</th>\n",
       "      <th>...</th>\n",
       "      <th>eps_to_price_trend</th>\n",
       "      <th>sales_to_price</th>\n",
       "      <th>sales_to_price_trend</th>\n",
       "      <th>fcf_calc</th>\n",
       "      <th>cash_to_price</th>\n",
       "      <th>cash_to_price_trend</th>\n",
       "      <th>div_to_price</th>\n",
       "      <th>div_to_price_trend</th>\n",
       "      <th>book_to_price</th>\n",
       "      <th>book_to_price_trend</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">IBM US Equity</th>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL US Equity</th>\n",
       "      <th>2024-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">IBM US Equity</th>\n",
       "      <th>2025-01-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AAPL US Equity</th>\n",
       "      <th>2025-01-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           cur_mkt_cap  px_last_splits  beta  volatility  \\\n",
       "ID             DATE                                                        \n",
       "IBM US Equity  2018-12-31          NaN             NaN   NaN         NaN   \n",
       "               2019-01-31          NaN             NaN   NaN         NaN   \n",
       "               2019-02-28          NaN             NaN   NaN         NaN   \n",
       "               2019-03-31          NaN             NaN   NaN         NaN   \n",
       "               2019-04-30          NaN             NaN   NaN         NaN   \n",
       "...                                ...             ...   ...         ...   \n",
       "AAPL US Equity 2024-12-31          NaN             NaN   NaN         NaN   \n",
       "IBM US Equity  2025-01-31          NaN             NaN   NaN         NaN   \n",
       "               2025-02-07          NaN             NaN   NaN         NaN   \n",
       "AAPL US Equity 2025-01-31          NaN             NaN   NaN         NaN   \n",
       "               2025-02-07          NaN             NaN   NaN         NaN   \n",
       "\n",
       "                           avg_volm_to_cap  volume_trend  residual_variance  \\\n",
       "ID             DATE                                                           \n",
       "IBM US Equity  2018-12-31              NaN           NaN                NaN   \n",
       "               2019-01-31              NaN           NaN                NaN   \n",
       "               2019-02-28              NaN           NaN                NaN   \n",
       "               2019-03-31              NaN           NaN                NaN   \n",
       "               2019-04-30              NaN           NaN                NaN   \n",
       "...                                    ...           ...                ...   \n",
       "AAPL US Equity 2024-12-31              NaN           NaN                NaN   \n",
       "IBM US Equity  2025-01-31              NaN           NaN                NaN   \n",
       "               2025-02-07              NaN           NaN                NaN   \n",
       "AAPL US Equity 2025-01-31              NaN           NaN                NaN   \n",
       "               2025-02-07              NaN           NaN                NaN   \n",
       "\n",
       "                           stock_return_1m  rs_1m  stock_return_2m  ...  \\\n",
       "ID             DATE                                                 ...   \n",
       "IBM US Equity  2018-12-31              NaN    NaN              NaN  ...   \n",
       "               2019-01-31              NaN    NaN              NaN  ...   \n",
       "               2019-02-28              NaN    NaN              NaN  ...   \n",
       "               2019-03-31              NaN    NaN              NaN  ...   \n",
       "               2019-04-30              NaN    NaN              NaN  ...   \n",
       "...                                    ...    ...              ...  ...   \n",
       "AAPL US Equity 2024-12-31              NaN    NaN              NaN  ...   \n",
       "IBM US Equity  2025-01-31              NaN    NaN              NaN  ...   \n",
       "               2025-02-07              NaN    NaN              NaN  ...   \n",
       "AAPL US Equity 2025-01-31              NaN    NaN              NaN  ...   \n",
       "               2025-02-07              NaN    NaN              NaN  ...   \n",
       "\n",
       "                           eps_to_price_trend  sales_to_price  \\\n",
       "ID             DATE                                             \n",
       "IBM US Equity  2018-12-31                 NaN             NaN   \n",
       "               2019-01-31                 NaN             NaN   \n",
       "               2019-02-28                 NaN             NaN   \n",
       "               2019-03-31                 NaN             NaN   \n",
       "               2019-04-30                 NaN             NaN   \n",
       "...                                       ...             ...   \n",
       "AAPL US Equity 2024-12-31                 NaN             NaN   \n",
       "IBM US Equity  2025-01-31                 NaN             NaN   \n",
       "               2025-02-07                 NaN             NaN   \n",
       "AAPL US Equity 2025-01-31                 NaN             NaN   \n",
       "               2025-02-07                 NaN             NaN   \n",
       "\n",
       "                           sales_to_price_trend  fcf_calc  cash_to_price  \\\n",
       "ID             DATE                                                        \n",
       "IBM US Equity  2018-12-31                   NaN       NaN            NaN   \n",
       "               2019-01-31                   NaN       NaN            NaN   \n",
       "               2019-02-28                   NaN       NaN            NaN   \n",
       "               2019-03-31                   NaN       NaN            NaN   \n",
       "               2019-04-30                   NaN       NaN            NaN   \n",
       "...                                         ...       ...            ...   \n",
       "AAPL US Equity 2024-12-31                   NaN       NaN            NaN   \n",
       "IBM US Equity  2025-01-31                   NaN       NaN            NaN   \n",
       "               2025-02-07                   NaN       NaN            NaN   \n",
       "AAPL US Equity 2025-01-31                   NaN       NaN            NaN   \n",
       "               2025-02-07                   NaN       NaN            NaN   \n",
       "\n",
       "                           cash_to_price_trend  div_to_price  \\\n",
       "ID             DATE                                            \n",
       "IBM US Equity  2018-12-31                  NaN           NaN   \n",
       "               2019-01-31                  NaN           NaN   \n",
       "               2019-02-28                  NaN           NaN   \n",
       "               2019-03-31                  NaN           NaN   \n",
       "               2019-04-30                  NaN           NaN   \n",
       "...                                        ...           ...   \n",
       "AAPL US Equity 2024-12-31                  NaN           NaN   \n",
       "IBM US Equity  2025-01-31                  NaN           NaN   \n",
       "               2025-02-07                  NaN           NaN   \n",
       "AAPL US Equity 2025-01-31                  NaN           NaN   \n",
       "               2025-02-07                  NaN           NaN   \n",
       "\n",
       "                           div_to_price_trend  book_to_price  \\\n",
       "ID             DATE                                            \n",
       "IBM US Equity  2018-12-31                 NaN            NaN   \n",
       "               2019-01-31                 NaN            NaN   \n",
       "               2019-02-28                 NaN            NaN   \n",
       "               2019-03-31                 NaN            NaN   \n",
       "               2019-04-30                 NaN            NaN   \n",
       "...                                       ...            ...   \n",
       "AAPL US Equity 2024-12-31                 NaN            NaN   \n",
       "IBM US Equity  2025-01-31                 NaN            NaN   \n",
       "               2025-02-07                 NaN            NaN   \n",
       "AAPL US Equity 2025-01-31                 NaN            NaN   \n",
       "               2025-02-07                 NaN            NaN   \n",
       "\n",
       "                           book_to_price_trend  \n",
       "ID             DATE                             \n",
       "IBM US Equity  2018-12-31                  NaN  \n",
       "               2019-01-31                  NaN  \n",
       "               2019-02-28                  NaN  \n",
       "               2019-03-31                  NaN  \n",
       "               2019-04-30                  NaN  \n",
       "...                                        ...  \n",
       "AAPL US Equity 2024-12-31                  NaN  \n",
       "IBM US Equity  2025-01-31                  NaN  \n",
       "               2025-02-07                  NaN  \n",
       "AAPL US Equity 2025-01-31                  NaN  \n",
       "               2025-02-07                  NaN  \n",
       "\n",
       "[150 rows x 31 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b4750-cdb5-467e-b490-a51d8edb1c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26392c75-575e-45d9-b871-7a40fb15d996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b26dec5b-83cb-4e31-841d-56102e2391c8",
   "metadata": {},
   "source": [
    "### testing dataframe "
   ]
  },
  {
   "cell_type": "raw",
   "id": "99eef62f-4fd3-4445-9b61-3447367812a2",
   "metadata": {},
   "source": [
    "np.random.seed(42)\n",
    "n_rows = 100\n",
    "data = {\n",
    "    'ID': np.random.choice(['A', 'B', 'C'], n_rows),\n",
    "    'DATE': pd.to_datetime('2023-01-01') + pd.to_timedelta(np.arange(n_rows), unit='D'),\n",
    "    'A': np.random.rand(n_rows),\n",
    "    'B': np.random.rand(n_rows),\n",
    "    'C': np.random.rand(n_rows),\n",
    "    'Y': 2 * np.random.rand(n_rows) + 0.5\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df = df.set_index('DATE') # Set DATE as index for proper rolling\n",
    "\n",
    "window_size = 20\n",
    "dependent_var = 'Y'\n",
    "independent_vars = ['A', 'B', 'C']\n",
    "\n",
    "def apply_rolling_regression(group):\n",
    "    \"\"\"Applies rolling regression to a group of data.\"\"\"\n",
    "    return rolling_regression(group, window_size, dependent_var, independent_vars)\n",
    "\n",
    "results_grouped = df.groupby('ID').apply(apply_rolling_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbe92f5-4c5f-4208-9b16-00fb47d8e479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0301b1fd-0bf1-4d0b-8267-33e717e5360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage with MultiIndex:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample DataFrame with MultiIndex\n",
    "np.random.seed(0)\n",
    "dates = pd.to_datetime(range(100), unit='D', origin=pd.Timestamp('2025-02-07'))\n",
    "levels = ['A', 'B']\n",
    "level_values = np.random.choice(levels, 100)\n",
    "multi_index = pd.MultiIndex.from_arrays([level_values, dates], names=['level', 'date'])\n",
    "data = np.random.randn(100, 3)\n",
    "df_multi = pd.DataFrame(data, columns=['var1', 'var2', 'dep_var'], index=multi_index)\n",
    "\n",
    "window_size = 20\n",
    "dependent_var = 'dep_var'\n",
    "independent_vars = ['var1', 'var2']\n",
    "\n",
    "# Perform OLS Rolling Regression (default)\n",
    "ols_results_multi = rolling_regression(df_multi, window_size, dependent_var, independent_vars)\n",
    "print(\"OLS Results with MultiIndex:\")\n",
    "print(ols_results_multi.head())\n",
    "print(ols_results_multi.index[:5]) # Print first 5 indices to verify MultiIndex is preserved\n",
    "\n",
    "# Perform Ridge Rolling Regression\n",
    "ridge_results_multi = rolling_regression(df_multi, window_size, dependent_var, independent_vars, reg_type='Ridge', alpha=0.5)\n",
    "print(\"\\nRidge Results with MultiIndex:\")\n",
    "print(ridge_results_multi.head())\n",
    "print(ridge_results_multi.index[:5]) # Print first 5 indices to verify MultiIndex is preserved\n",
    "\n",
    "# Perform Lasso Rolling Regression\n",
    "lasso_results_multi = rolling_regression(df_multi, window_size, dependent_var, independent_vars, reg_type='Lasso', alpha=0.1)\n",
    "print(\"\\nLasso Results with MultiIndex:\")\n",
    "print(lasso_results_multi.head())\n",
    "print(lasso_results_multi.index[:5]) # Print first 5 indices to verify MultiIndex is preserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a10061-79fd-4140-aca9-94380488f75b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
