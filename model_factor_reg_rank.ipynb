{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84b4f2f1-2832-4cf8-be45-39c5003f8abf",
   "metadata": {},
   "source": [
    "### read data and calc returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6926e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a72fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_analytics_univ_rty_2014_m.csv', parse_dates = ['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6fe0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383b59fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [ c for c in df.columns if 'idx_return' in c ]\n",
    "\n",
    "\n",
    "drop_cols1 = ['open',\n",
    " 'high',\n",
    " 'low',\n",
    " 'close',\n",
    " 'volume',\n",
    " 'bid',\n",
    " 'ask',\n",
    " 'baspd',\n",
    " 'idx_close',\n",
    " 'forward_return',\n",
    " 'idx_forward_return',\n",
    " 'relative_return',\n",
    " 'stock_excess_return']\n",
    "\n",
    "drop_cols1 = [ c for c in drop_cols1 if c in df.columns.tolist() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc42bd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.drop(columns = (drop_cols + drop_cols1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb67bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats and returns are as of given date\n",
    "# so either shift returns up, or stats down to do regression on returns vs stats as of beginning of returns period \n",
    "# lets shift stats down to align with returns end date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b329cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift down everything except ID, DATE, stock_return \n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514f16f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_cols = [ c for c in df.columns if c not in ['ID', 'DATE', 'stock_return'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b008f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[shift_cols] = df.groupby('ID')[shift_cols].shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dfed4a-6c12-4b5a-bd76-a7108179e09f",
   "metadata": {},
   "source": [
    "### functions - rolling reg / var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2033c2a9-5a5f-453c-8db9-f4b21374fd76",
   "metadata": {},
   "source": [
    "### calculate simple returns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e6a3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['DATE','ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f260bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_dates = df.apply(lambda x: x.first_valid_index())\n",
    "\n",
    "first_dates = first_dates.rename('first_idx').to_frame()\n",
    "value_columns = df.columns.difference(['ID', 'DATE'])\n",
    "\n",
    "# For each column\n",
    "dseries = pd.DataFrame()\n",
    "for column in value_columns:\n",
    "    first_date = df[df[column].notna()]['DATE'].min()\n",
    "    last_date = df[df[column].notna()]['DATE'].max()\n",
    "    first_dates.loc[column,'first_date'] = first_date\n",
    "    first_dates.loc[column,'last_date'] = last_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d224ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ded34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3c2dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = df.set_index(['ID','DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48648934",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d76b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "cutoff_date = '2015-12-31'\n",
    "fdf = fdf[fdf.index.get_level_values('DATE') > cutoff_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2a7a63-c260-4f25-bdd1-a6ee8583bbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf[value_columns] = fdf.groupby('DATE')[value_columns].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52e0779",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ycols = value_columns.difference(['stock_return'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5663d4-3835-4568-a76b-c85dbcf97f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# df[numcols] = df[numcols].groupby('ITERATION_DATE').transform(lambda x: winsorize(x, limits = (0.01,0.01)))\n",
    "fdf[Ycols] = fdf[Ycols].groupby('DATE').transform(lambda x: zscore(x).clip(-3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34316bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_sectional_regression(df, dependent_var, independent_vars, reg_type='OLS', alpha=1.0):\n",
    "    \"\"\"\n",
    "    Performs regression in parallel for each group using joblib, with options for OLS, Ridge, and Lasso.\n",
    "    Returns np.nan for coefficients when X or y contains NaN values.\n",
    "\n",
    "    Args:\n",
    "        df: Pandas DataFrame containing the data with columns ID, DATE, and other variables\n",
    "        dependent_var: Name of the dependent variable column\n",
    "        independent_vars: List of names of independent variable columns\n",
    "        reg_type: Type of regression to perform ('OLS', 'Ridge', 'Lasso'). Default is 'OLS'\n",
    "        alpha: Regularization strength for Ridge and Lasso. Default is 1.0\n",
    "\n",
    "    Returns:\n",
    "        Pandas DataFrame with the regression coefficients for each ID and DATE\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "    from joblib import Parallel, delayed\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    def _regress_group(group_data):\n",
    "        X = group_data[independent_vars].values\n",
    "        y = group_data[dependent_var].values.reshape(-1,1)\n",
    "        \n",
    "        # Return NaN coefficients if data contains NaN\n",
    "        if np.any(np.isnan(X)) or np.any(np.isnan(y)):\n",
    "            return pd.Series({\n",
    "                'DATE': group_data['DATE'].iloc[0],\n",
    "                'intercept': np.nan,\n",
    "                **dict(zip(independent_vars, [np.nan] * len(independent_vars)))\n",
    "            })\n",
    "            \n",
    "        if reg_type.upper() == 'OLS':\n",
    "            model = LinearRegression()\n",
    "        elif reg_type.upper() == 'RIDGE':\n",
    "            model = Ridge(alpha=alpha)\n",
    "        elif reg_type.upper() == 'LASSO':\n",
    "            model = Lasso(alpha=alpha)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid reg_type. Choose 'OLS', 'Ridge', or 'Lasso'.\")\n",
    "            \n",
    "        model.fit(X, y)\n",
    "        coefs = model.coef_.flatten()\n",
    "        intercept = model.intercept_\n",
    "        \n",
    "        return pd.Series({\n",
    "            'DATE': group_data['DATE'].iloc[0],\n",
    "            'intercept': intercept[0] if isinstance(intercept, np.ndarray) else intercept,\n",
    "            **dict(zip(independent_vars, coefs))\n",
    "        })\n",
    "    \n",
    "    # Group by DATE and perform regression\n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(_regress_group)(group) \n",
    "        for _, group in df.groupby('DATE')\n",
    "    )\n",
    "    \n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.set_index('DATE')\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Let's create an example to demonstrate the usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe6bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = fdf.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be544947",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = cross_sectional_regression(fdf, dependent_var='stock_return', independent_vars=Ycols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42183ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = betas.rolling(12).mean()\n",
    "betas = betas.reset_index().set_index('DATE')\n",
    "betas.index = pd.to_datetime(betas.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e83783",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_shifted = pd.concat([\n",
    "    betas.shift(1),\n",
    "    pd.DataFrame([betas.iloc[-1]], index=[betas.index[-1] + pd.offsets.MonthEnd(1)])\n",
    "])\n",
    "betas_shifted.index.name = 'DATE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5a62dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for manual confirmation \n",
    "betas_shifted[list(Ycols) + ['intercept']].to_csv('betas.csv')\n",
    "fdf[['ID','DATE'] + list(Ycols)].to_csv('fdf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5697d282",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = fdf.set_index(['ID','DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aac7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "yfit = fdf[Ycols].assign(intercept = 1).mul(betas_shifted, level = 'DATE').sum(axis = 1).rename('exp_ret').to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d29fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "yfit['quantile'] = yfit.groupby('DATE', group_keys = False)['exp_ret'].apply(lambda x: pd.cut(x, 10, labels = False)).rename('quantile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890af196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using stats as of date \n",
    "# Dec 1st stats (shifted) with Dec end returns gives Dec beta. \n",
    "# avearge of Jan to Dec betas gives Dec average beta \n",
    "# Dec beta with Dec returns gives dec ranks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afefd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "yfit = yfit.merge(fdf[['stock_return']], left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ee8d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is ignoring a lot of the features, but need this for now to proceed with just model fitting \n",
    "# goal is daily data, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4674e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "yfit_clean = yfit[yfit.index.get_level_values('DATE')> pd.Timestamp('2016-12-31')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b4750-cdb5-467e-b490-a51d8edb1c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yfit_clean.to_csv('rty_2014_smallfeatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a15e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what output do we need?\n",
    "# 1. betas \n",
    "# 2. tstats\n",
    "# 3. ranks and realized returns for decile testing => goes to rank backtester \n",
    "# 4. current portfolio \n",
    "# 5. can redo ranks based on combining top betas differently \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7084bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdd3ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
